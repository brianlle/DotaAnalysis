{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cmx\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import json\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import string\n",
    "import math\n",
    "from dota_function_definitions import create_dota_dataframe2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "96,004 matches (Very High skill, all matchmaking modes) were collected between February 29, 2016 and March 6, 2016. The matches all occurred while the game was on patch 6.86d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dotaFrame = pd.read_csv('dotaFrame_20160229_to_20160306.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('heroes.txt', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    heroDict = {rows[0]:rows[1] for rows in reader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96004"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dotaFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.text.Text at 0xcf47828>,\n",
       " <matplotlib.text.Text at 0xcf34630>,\n",
       " <matplotlib.text.Text at 0xcf47c50>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAEZCAYAAACuIuMVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ns6z+P/5/FXtt4h2lAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcde1860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "ax = dotaFrame['Match Length (s)'].hist()\n",
    "ax.set(xlabel='Length (s)', ylabel='Count', title='Histogram of Match Lengths')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now imported a fairly large number of matches into a pandas dataframe. The most played game modes are 1 (All Pick) and 22 (Ranked All Pick) which are the only two game modes where all ten players have complete freedom of choice in picking their hero. These two modes embody the chaos that is the 'draft' portion of public matchmaking Dota 2 game, so we will only look at matches for these two game modes in our model. We will also cut out any matches ending before 10 minutes as games that end that early tend to have some skewed factor such as a player abandoning the game early."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dotaFrame = pd.concat([dotaFrame[dotaFrame['Game Mode']==1], dotaFrame[dotaFrame['Game Mode']==22]])\n",
    "dotaFrame = dotaFrame[dotaFrame['Match Length (s)']>599]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 111 heroes currently in the game using hero IDs 1 to 113 (IDs 24 and 108 are unused for reasons unknown). To perform logistic regression, we will use 113 on/off switches for each team indicating whether or not that particular hero is present on the team in a game. Since the current dataframe records the hero for each particular player slot as opposed for just a particular team, we will combine the player slots for each team into a single dataframe cell. From there, we can use the get_dummies() function obtain our 226 switches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dotaFrame['Radiant']='R'+dotaFrame['Radiant 1'].map(str)+','+'R'+dotaFrame['Radiant 2'].map(str)+','+'R'+dotaFrame['Radiant 3'].map(str)+','+'R'+dotaFrame['Radiant 4'].map(str)+','+'R'+dotaFrame['Radiant 5'].map(str)\n",
    "dotaFrame['Dire']='D'+dotaFrame['Dire 1'].map(str)+','+'D'+dotaFrame['Dire 2'].map(str)+','+'D'+dotaFrame['Dire 3'].map(str)+','+'D'+dotaFrame['Dire 4'].map(str)+','+'D'+dotaFrame['Dire 5'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dotaFrameLogitRadiant = dotaFrame['Radiant'].str.get_dummies(sep=',')\n",
    "dotaFrameLogitDire = dotaFrame['Dire'].str.get_dummies(sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dotaFrameLogit = dotaFrameLogitRadiant.join(dotaFrameLogitDire)\n",
    "dotaFrameLogit['Intercept']=1\n",
    "dotaFrameLogit['Radiant Win Y/N'] = dotaFrame['Radiant Win Y/N']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add an intercept term and the winning team information to the resultant dataframe. As seen below, all the data is now represented as 0s and 1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R1</th>\n",
       "      <th>R10</th>\n",
       "      <th>R100</th>\n",
       "      <th>R101</th>\n",
       "      <th>R102</th>\n",
       "      <th>R103</th>\n",
       "      <th>R104</th>\n",
       "      <th>R105</th>\n",
       "      <th>R106</th>\n",
       "      <th>R107</th>\n",
       "      <th>...</th>\n",
       "      <th>D92</th>\n",
       "      <th>D93</th>\n",
       "      <th>D94</th>\n",
       "      <th>D95</th>\n",
       "      <th>D96</th>\n",
       "      <th>D97</th>\n",
       "      <th>D98</th>\n",
       "      <th>D99</th>\n",
       "      <th>Intercept</th>\n",
       "      <th>Radiant Win Y/N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 224 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    R1  R10  R100  R101  R102  R103  R104  R105  R106  R107       ...         \\\n",
       "2    0    0     0     0     0     0     1     0     0     0       ...          \n",
       "5    0    0     0     0     0     0     0     0     0     0       ...          \n",
       "6    1    0     0     0     0     0     0     0     0     0       ...          \n",
       "10   0    1     0     0     0     0     0     0     0     0       ...          \n",
       "14   0    0     0     0     0     0     0     0     0     0       ...          \n",
       "17   0    0     0     0     0     0     0     0     0     0       ...          \n",
       "21   0    1     0     0     0     0     0     0     0     0       ...          \n",
       "25   0    0     0     1     0     0     0     0     0     0       ...          \n",
       "35   0    0     0     0     0     0     0     1     0     0       ...          \n",
       "37   0    0     0     0     0     0     1     0     0     0       ...          \n",
       "\n",
       "    D92  D93  D94  D95  D96  D97  D98  D99  Intercept  Radiant Win Y/N  \n",
       "2     0    0    0    0    0    0    0    0          1             True  \n",
       "5     0    0    0    0    0    0    0    0          1            False  \n",
       "6     0    0    0    0    0    0    0    0          1             True  \n",
       "10    0    0    0    0    0    0    0    0          1            False  \n",
       "14    0    0    0    0    0    0    0    0          1             True  \n",
       "17    0    0    0    0    0    0    0    0          1            False  \n",
       "21    0    0    0    0    0    0    0    0          1            False  \n",
       "25    0    0    0    0    0    0    0    0          1             True  \n",
       "35    0    0    0    0    0    0    0    0          1            False  \n",
       "37    0    0    0    0    0    0    0    0          1            False  \n",
       "\n",
       "[10 rows x 224 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotaFrameLogit.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll split the data into a training set and a testing set. The model will be fit to the training set, and then we will test the model's efficacy on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dotaFrameTrain, dotaFrameTest = train_test_split(dotaFrameLogit, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65782"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dotaFrameTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16446"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dotaFrameTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainColumn = list(dotaFrameLogit.columns.values)[0:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we utilize statsmodels' logistic regression function Logit() to model our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = sm.Logit(dotaFrameTrain['Radiant Win Y/N'], dotaFrameTrain[trainColumn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.625832\n",
      "         Iterations: 105\n",
      "         Function evaluations: 106\n",
      "         Gradient evaluations: 106\n"
     ]
    }
   ],
   "source": [
    "result = model.fit(method='bfgs', maxiter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:        Radiant Win Y/N   No. Observations:                65782\n",
      "Model:                          Logit   Df Residuals:                    65561\n",
      "Method:                           MLE   Df Model:                          220\n",
      "Date:                Sun, 06 Mar 2016   Pseudo R-squ.:                 0.08598\n",
      "Time:                        18:33:30   Log-Likelihood:                -41168.\n",
      "converged:                       True   LL-Null:                       -45041.\n",
      "                                        LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "R1            -0.6289        nan        nan        nan           nan       nan\n",
      "R10           -0.2764        nan        nan        nan           nan       nan\n",
      "R100           0.0227        nan        nan        nan           nan       nan\n",
      "R101          -0.1381        nan        nan        nan           nan       nan\n",
      "R102           0.3868        nan        nan        nan           nan       nan\n",
      "R103           0.0538        nan        nan        nan           nan       nan\n",
      "R104          -0.1348        nan        nan        nan           nan       nan\n",
      "R105          -0.2411        nan        nan        nan           nan       nan\n",
      "R106          -0.2520        nan        nan        nan           nan       nan\n",
      "R107           0.1501        nan        nan        nan           nan       nan\n",
      "R109          -0.2842        nan        nan        nan           nan       nan\n",
      "R11           -0.4409        nan        nan        nan           nan       nan\n",
      "R110           0.0842        nan        nan        nan           nan       nan\n",
      "R111          -0.2126        nan        nan        nan           nan       nan\n",
      "R112           0.0148        nan        nan        nan           nan       nan\n",
      "R113          -0.1532        nan        nan        nan           nan       nan\n",
      "R12           -0.3078        nan        nan        nan           nan       nan\n",
      "R13           -0.2561        nan        nan        nan           nan       nan\n",
      "R14            0.2577        nan        nan        nan           nan       nan\n",
      "R15           -0.1582        nan        nan        nan           nan       nan\n",
      "R16            0.1068        nan        nan        nan           nan       nan\n",
      "R17           -0.7427        nan        nan        nan           nan       nan\n",
      "R18            0.0202        nan        nan        nan           nan       nan\n",
      "R19           -0.1571        nan        nan        nan           nan       nan\n",
      "R2            -0.4119        nan        nan        nan           nan       nan\n",
      "R20            0.3706        nan        nan        nan           nan       nan\n",
      "R21           -0.2097        nan        nan        nan           nan       nan\n",
      "R22            0.4627        nan        nan        nan           nan       nan\n",
      "R23           -0.0532        nan        nan        nan           nan       nan\n",
      "R25           -0.1156        nan        nan        nan           nan       nan\n",
      "R26            0.0349        nan        nan        nan           nan       nan\n",
      "R27            0.2285        nan        nan        nan           nan       nan\n",
      "R28            0.1779        nan        nan        nan           nan       nan\n",
      "R29            0.0317        nan        nan        nan           nan       nan\n",
      "R3             0.0706        nan        nan        nan           nan       nan\n",
      "R30            0.2923        nan        nan        nan           nan       nan\n",
      "R31            0.3497        nan        nan        nan           nan       nan\n",
      "R32            0.1047        nan        nan        nan           nan       nan\n",
      "R33            0.2962        nan        nan        nan           nan       nan\n",
      "R34           -0.1191        nan        nan        nan           nan       nan\n",
      "R35           -0.3556        nan        nan        nan           nan       nan\n",
      "R36            0.5946        nan        nan        nan           nan       nan\n",
      "R37            0.2728        nan        nan        nan           nan       nan\n",
      "R38            0.3688        nan        nan        nan           nan       nan\n",
      "R39           -0.3721        nan        nan        nan           nan       nan\n",
      "R4            -0.2166        nan        nan        nan           nan       nan\n",
      "R40            0.4317        nan        nan        nan           nan       nan\n",
      "R41            0.0785        nan        nan        nan           nan       nan\n",
      "R42           -0.0343        nan        nan        nan           nan       nan\n",
      "R43            0.0458        nan        nan        nan           nan       nan\n",
      "R44           -0.4454        nan        nan        nan           nan       nan\n",
      "R45            0.3817        nan        nan        nan           nan       nan\n",
      "R46            0.0459        nan        nan        nan           nan       nan\n",
      "R47            0.1092        nan        nan        nan           nan       nan\n",
      "R48           -0.0378        nan        nan        nan           nan       nan\n",
      "R49           -0.0677        nan        nan        nan           nan       nan\n",
      "R5             0.3721        nan        nan        nan           nan       nan\n",
      "R50            0.3210        nan        nan        nan           nan       nan\n",
      "R51            0.0357        nan        nan        nan           nan       nan\n",
      "R52           -0.1125        nan        nan        nan           nan       nan\n",
      "R53           -0.0272        nan        nan        nan           nan       nan\n",
      "R54           -0.2074        nan        nan        nan           nan       nan\n",
      "R55            0.0610        nan        nan        nan           nan       nan\n",
      "R56            0.1005        nan        nan        nan           nan       nan\n",
      "R57            0.6095        nan        nan        nan           nan       nan\n",
      "R58            0.2074        nan        nan        nan           nan       nan\n",
      "R59           -0.1974        nan        nan        nan           nan       nan\n",
      "R6             0.1595        nan        nan        nan           nan       nan\n",
      "R60            0.2207        nan        nan        nan           nan       nan\n",
      "R61           -0.1038        nan        nan        nan           nan       nan\n",
      "R62            0.4764        nan        nan        nan           nan       nan\n",
      "R63            0.1000        nan        nan        nan           nan       nan\n",
      "R64            0.2378        nan        nan        nan           nan       nan\n",
      "R65           -0.1671        nan        nan        nan           nan       nan\n",
      "R66            0.5298        nan        nan        nan           nan       nan\n",
      "R67           -0.1045        nan        nan        nan           nan       nan\n",
      "R68           -0.2147        nan        nan        nan           nan       nan\n",
      "R69            0.0714        nan        nan        nan           nan       nan\n",
      "R7             0.1070        nan        nan        nan           nan       nan\n",
      "R70            0.1891        nan        nan        nan           nan       nan\n",
      "R71            0.1702        nan        nan        nan           nan       nan\n",
      "R72           -0.1708        nan        nan        nan           nan       nan\n",
      "R73           -0.2183        nan        nan        nan           nan       nan\n",
      "R74            0.0996        nan        nan        nan           nan       nan\n",
      "R75            0.2347        nan        nan        nan           nan       nan\n",
      "R76            0.0810        nan        nan        nan           nan       nan\n",
      "R77            0.3514        nan        nan        nan           nan       nan\n",
      "R78           -0.1537        nan        nan        nan           nan       nan\n",
      "R79           -0.0578        nan        nan        nan           nan       nan\n",
      "R8             0.0089        nan        nan        nan           nan       nan\n",
      "R80            0.0242        nan        nan        nan           nan       nan\n",
      "R81            0.1420        nan        nan        nan           nan       nan\n",
      "R82           -0.5023        nan        nan        nan           nan       nan\n",
      "R83            0.2586        nan        nan        nan           nan       nan\n",
      "R84            0.2327        nan        nan        nan           nan       nan\n",
      "R85            0.3027        nan        nan        nan           nan       nan\n",
      "R86            0.0001        nan        nan        nan           nan       nan\n",
      "R87            0.1825        nan        nan        nan           nan       nan\n",
      "R88            0.1628        nan        nan        nan           nan       nan\n",
      "R89           -0.7245        nan        nan        nan           nan       nan\n",
      "R9             0.2890        nan        nan        nan           nan       nan\n",
      "R90           -0.0207        nan        nan        nan           nan       nan\n",
      "R91           -0.1581        nan        nan        nan           nan       nan\n",
      "R92            0.1940        nan        nan        nan           nan       nan\n",
      "R93           -0.2880        nan        nan        nan           nan       nan\n",
      "R94           -0.0457        nan        nan        nan           nan       nan\n",
      "R95           -0.3734        nan        nan        nan           nan       nan\n",
      "R96           -0.1427        nan        nan        nan           nan       nan\n",
      "R97           -0.2593        nan        nan        nan           nan       nan\n",
      "R98           -0.3833        nan        nan        nan           nan       nan\n",
      "R99           -0.1817        nan        nan        nan           nan       nan\n",
      "D1             0.4954   1.88e+05   2.63e-06      1.000     -3.68e+05  3.68e+05\n",
      "D10            0.4069   1.88e+05   2.16e-06      1.000     -3.68e+05  3.68e+05\n",
      "D100           0.0634   1.88e+05   3.37e-07      1.000     -3.68e+05  3.68e+05\n",
      "D101           0.0032   1.88e+05   1.71e-08      1.000     -3.68e+05  3.68e+05\n",
      "D102          -0.4199   1.88e+05  -2.23e-06      1.000     -3.68e+05  3.68e+05\n",
      "D103          -0.0339   1.88e+05   -1.8e-07      1.000     -3.68e+05  3.68e+05\n",
      "D104           0.0555   1.88e+05   2.95e-07      1.000     -3.68e+05  3.68e+05\n",
      "D105           0.4094   1.88e+05   2.18e-06      1.000     -3.68e+05  3.68e+05\n",
      "D106           0.3008   1.88e+05    1.6e-06      1.000     -3.68e+05  3.68e+05\n",
      "D107          -0.1559   1.88e+05  -8.29e-07      1.000     -3.68e+05  3.68e+05\n",
      "D109           0.3092   1.88e+05   1.64e-06      1.000     -3.68e+05  3.68e+05\n",
      "D11            0.4483   1.88e+05   2.38e-06      1.000     -3.68e+05  3.68e+05\n",
      "D110          -0.0533   1.88e+05  -2.83e-07      1.000     -3.68e+05  3.68e+05\n",
      "D111           0.0507   1.88e+05   2.69e-07      1.000     -3.68e+05  3.68e+05\n",
      "D112          -0.1472   1.88e+05  -7.83e-07      1.000     -3.68e+05  3.68e+05\n",
      "D113           0.2578   1.88e+05   1.37e-06      1.000     -3.68e+05  3.68e+05\n",
      "D12            0.3190   1.88e+05    1.7e-06      1.000     -3.68e+05  3.68e+05\n",
      "D13            0.2031   1.88e+05   1.08e-06      1.000     -3.68e+05  3.68e+05\n",
      "D14           -0.1517   1.88e+05  -8.07e-07      1.000     -3.68e+05  3.68e+05\n",
      "D15            0.1372   1.88e+05    7.3e-07      1.000     -3.68e+05  3.68e+05\n",
      "D16           -0.0432   1.88e+05   -2.3e-07      1.000     -3.68e+05  3.68e+05\n",
      "D17            0.6249   1.88e+05   3.32e-06      1.000     -3.68e+05  3.68e+05\n",
      "D18           -0.0927   1.88e+05  -4.93e-07      1.000     -3.68e+05  3.68e+05\n",
      "D19            0.3486   1.88e+05   1.85e-06      1.000     -3.68e+05  3.68e+05\n",
      "D2             0.3395   1.88e+05   1.81e-06      1.000     -3.68e+05  3.68e+05\n",
      "D20           -0.3543   1.88e+05  -1.88e-06      1.000     -3.68e+05  3.68e+05\n",
      "D21            0.1724   1.88e+05   9.17e-07      1.000     -3.68e+05  3.68e+05\n",
      "D22           -0.2928   1.88e+05  -1.56e-06      1.000     -3.68e+05  3.68e+05\n",
      "D23            0.0547   1.88e+05   2.91e-07      1.000     -3.68e+05  3.68e+05\n",
      "D25            0.2173   1.88e+05   1.16e-06      1.000     -3.68e+05  3.68e+05\n",
      "D26            0.0291   1.88e+05   1.55e-07      1.000     -3.68e+05  3.68e+05\n",
      "D27           -0.2530   1.88e+05  -1.35e-06      1.000     -3.68e+05  3.68e+05\n",
      "D28           -0.1328   1.88e+05  -7.07e-07      1.000     -3.68e+05  3.68e+05\n",
      "D29           -0.0475   1.88e+05  -2.52e-07      1.000     -3.68e+05  3.68e+05\n",
      "D3             0.0359   1.88e+05   1.91e-07      1.000     -3.68e+05  3.68e+05\n",
      "D30           -0.2994   1.88e+05  -1.59e-06      1.000     -3.68e+05  3.68e+05\n",
      "D31           -0.3569   1.88e+05   -1.9e-06      1.000     -3.68e+05  3.68e+05\n",
      "D32            0.0561   1.88e+05   2.98e-07      1.000     -3.68e+05  3.68e+05\n",
      "D33           -0.3266   1.88e+05  -1.74e-06      1.000     -3.68e+05  3.68e+05\n",
      "D34            0.1547   1.88e+05   8.23e-07      1.000     -3.68e+05  3.68e+05\n",
      "D35            0.3857   1.88e+05   2.05e-06      1.000     -3.68e+05  3.68e+05\n",
      "D36           -0.5604   1.88e+05  -2.98e-06      1.000     -3.68e+05  3.68e+05\n",
      "D37           -0.3500   1.88e+05  -1.86e-06      1.000     -3.68e+05  3.68e+05\n",
      "D38           -0.3113   1.88e+05  -1.66e-06      1.000     -3.68e+05  3.68e+05\n",
      "D39            0.4065   1.88e+05   2.16e-06      1.000     -3.68e+05  3.68e+05\n",
      "D4             0.2670   1.88e+05   1.42e-06      1.000     -3.68e+05  3.68e+05\n",
      "D40           -0.2775   1.88e+05  -1.48e-06      1.000     -3.68e+05  3.68e+05\n",
      "D41            0.0062   1.88e+05   3.32e-08      1.000     -3.68e+05  3.68e+05\n",
      "D42            0.0996   1.88e+05    5.3e-07      1.000     -3.68e+05  3.68e+05\n",
      "D43           -0.0442   1.88e+05  -2.35e-07      1.000     -3.68e+05  3.68e+05\n",
      "D44            0.3880   1.88e+05   2.06e-06      1.000     -3.68e+05  3.68e+05\n",
      "D45           -0.4781   1.88e+05  -2.54e-06      1.000     -3.68e+05  3.68e+05\n",
      "D46            0.0322   1.88e+05   1.72e-07      1.000     -3.68e+05  3.68e+05\n",
      "D47           -0.1092   1.88e+05  -5.81e-07      1.000     -3.68e+05  3.68e+05\n",
      "D48           -0.0830   1.88e+05  -4.41e-07      1.000     -3.68e+05  3.68e+05\n",
      "D49            0.1963   1.88e+05   1.04e-06      1.000     -3.68e+05  3.68e+05\n",
      "D5            -0.2854   1.88e+05  -1.52e-06      1.000     -3.68e+05  3.68e+05\n",
      "D50           -0.3931   1.88e+05  -2.09e-06      1.000     -3.68e+05  3.68e+05\n",
      "D51            0.0413   1.88e+05    2.2e-07      1.000     -3.68e+05  3.68e+05\n",
      "D52            0.2484   1.88e+05   1.32e-06      1.000     -3.68e+05  3.68e+05\n",
      "D53           -0.0334   1.88e+05  -1.78e-07      1.000     -3.68e+05  3.68e+05\n",
      "D54            0.2686   1.88e+05   1.43e-06      1.000     -3.68e+05  3.68e+05\n",
      "D55            0.0180   1.88e+05   9.59e-08      1.000     -3.68e+05  3.68e+05\n",
      "D56           -0.0833   1.88e+05  -4.43e-07      1.000     -3.68e+05  3.68e+05\n",
      "D57           -0.5847   1.88e+05  -3.11e-06      1.000     -3.68e+05  3.68e+05\n",
      "D58           -0.1520   1.88e+05  -8.08e-07      1.000     -3.68e+05  3.68e+05\n",
      "D59            0.1036   1.88e+05   5.51e-07      1.000     -3.68e+05  3.68e+05\n",
      "D6            -0.2684   1.88e+05  -1.43e-06      1.000     -3.68e+05  3.68e+05\n",
      "D60           -0.0953   1.88e+05  -5.07e-07      1.000     -3.68e+05  3.68e+05\n",
      "D61            0.0090   1.88e+05   4.78e-08      1.000     -3.68e+05  3.68e+05\n",
      "D62           -0.3816   1.88e+05  -2.03e-06      1.000     -3.68e+05  3.68e+05\n",
      "D63           -0.1257   1.88e+05  -6.69e-07      1.000     -3.68e+05  3.68e+05\n",
      "D64           -0.2175   1.88e+05  -1.16e-06      1.000     -3.68e+05  3.68e+05\n",
      "D65            0.1957   1.88e+05   1.04e-06      1.000     -3.68e+05  3.68e+05\n",
      "D66           -0.5134   1.88e+05  -2.73e-06      1.000     -3.68e+05  3.68e+05\n",
      "D67            0.1669   1.88e+05   8.88e-07      1.000     -3.68e+05  3.68e+05\n",
      "D68            0.1892   1.88e+05   1.01e-06      1.000     -3.68e+05  3.68e+05\n",
      "D69           -0.0216   1.88e+05  -1.15e-07      1.000     -3.68e+05  3.68e+05\n",
      "D7            -0.0641   1.88e+05  -3.41e-07      1.000     -3.68e+05  3.68e+05\n",
      "D70           -0.2432   1.88e+05  -1.29e-06      1.000     -3.68e+05  3.68e+05\n",
      "D71           -0.2866   1.88e+05  -1.52e-06      1.000     -3.68e+05  3.68e+05\n",
      "D72            0.1532   1.88e+05   8.15e-07      1.000     -3.68e+05  3.68e+05\n",
      "D73            0.1922   1.88e+05   1.02e-06      1.000     -3.68e+05  3.68e+05\n",
      "D74            0.0089   1.88e+05   4.74e-08      1.000     -3.68e+05  3.68e+05\n",
      "D75           -0.1297   1.88e+05   -6.9e-07      1.000     -3.68e+05  3.68e+05\n",
      "D76           -0.1217   1.88e+05  -6.47e-07      1.000     -3.68e+05  3.68e+05\n",
      "D77           -0.3876   1.88e+05  -2.06e-06      1.000     -3.68e+05  3.68e+05\n",
      "D78            0.0744   1.88e+05   3.96e-07      1.000     -3.68e+05  3.68e+05\n",
      "D79            0.0644   1.88e+05   3.42e-07      1.000     -3.68e+05  3.68e+05\n",
      "D8            -0.0160   1.88e+05   -8.5e-08      1.000     -3.68e+05  3.68e+05\n",
      "D80           -0.0366   1.88e+05  -1.95e-07      1.000     -3.68e+05  3.68e+05\n",
      "D81           -0.1183   1.88e+05  -6.29e-07      1.000     -3.68e+05  3.68e+05\n",
      "D82            0.4631   1.88e+05   2.46e-06      1.000     -3.68e+05  3.68e+05\n",
      "D83           -0.1940   1.88e+05  -1.03e-06      1.000     -3.68e+05  3.68e+05\n",
      "D84           -0.2390   1.88e+05  -1.27e-06      1.000     -3.68e+05  3.68e+05\n",
      "D85           -0.3711   1.88e+05  -1.97e-06      1.000     -3.68e+05  3.68e+05\n",
      "D86           -0.0131   1.88e+05  -6.97e-08      1.000     -3.68e+05  3.68e+05\n",
      "D87           -0.0747   1.88e+05  -3.98e-07      1.000     -3.68e+05  3.68e+05\n",
      "D88           -0.0469   1.88e+05   -2.5e-07      1.000     -3.68e+05  3.68e+05\n",
      "D89            0.5670   1.88e+05   3.02e-06      1.000     -3.68e+05  3.68e+05\n",
      "D9            -0.1692   1.88e+05     -9e-07      1.000     -3.68e+05  3.68e+05\n",
      "D90           -0.0478   1.88e+05  -2.54e-07      1.000     -3.68e+05  3.68e+05\n",
      "D91            0.0580   1.88e+05   3.09e-07      1.000     -3.68e+05  3.68e+05\n",
      "D92           -0.0461   1.88e+05  -2.45e-07      1.000     -3.68e+05  3.68e+05\n",
      "D93            0.3255   1.88e+05   1.73e-06      1.000     -3.68e+05  3.68e+05\n",
      "D94            0.1297   1.88e+05    6.9e-07      1.000     -3.68e+05  3.68e+05\n",
      "D95            0.3089   1.88e+05   1.64e-06      1.000     -3.68e+05  3.68e+05\n",
      "D96            0.1442   1.88e+05   7.67e-07      1.000     -3.68e+05  3.68e+05\n",
      "D97            0.2463   1.88e+05   1.31e-06      1.000     -3.68e+05  3.68e+05\n",
      "D98            0.3782   1.88e+05   2.01e-06      1.000     -3.68e+05  3.68e+05\n",
      "D99            0.2485   1.88e+05   1.32e-06      1.000     -3.68e+05  3.68e+05\n",
      "Intercept      0.1483        nan        nan        nan           nan       nan\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainingPrediction = result.pred_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the confusion matrix to visualize how well the model does against the training set. Tested against the data used to form the model itself, it predicts ~64.9% of the matches successfully. Interestingly, the model seems to misinterpret Dire Wins as Radiant Wins more often than Radiant Wins as Dire Wins. The model seems to be much better at predicting Radiant wins in general, possibly because upon closer inspection, Radiant wins approximately 56.5% of the time and not a randomized coin flip 50% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x10f7b5c0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWkAAAEKCAYAAADQG6S6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1127f748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.heatmap(trainingPrediction, annot = True, fmt = \".6g\", xticklabels = ['Dire W', 'Radiant W'], yticklabels = ['Dire W', 'Radiant W'])\n",
    "ax.set_title(\"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56489617220516253"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotaFrameTrain['Radiant Win Y/N'].mean()    #percent of matches where Radiant won"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the model to predict matches where the Radiant team wins and matches where the Radiant team loses. Luckily, we have that testing dataset available for use! Let's use that below to find ypred, the array of predicted Radiant W/Ls, and compare that to ytest, the array of actual Radiant W/Ls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ypred = result.predict(dotaFrameTest[trainColumn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.69164826,  0.80311574,  0.60981552, ...,  0.80621999,\n",
       "        0.72275008,  0.79649596])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ypred = ypred.round().astype(int)    #convert probabilities to predicted win or loss for Radiant team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ytest = np.ravel(dotaFrameTest['Radiant Win Y/N']).astype(int)  #convert binary dataframe series to int numpy array for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64818192873647085"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ypred, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Using this logistic regression model, there is a ~64.8% correct prediction rate on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
